{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nyqqVTKJX9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwp6Xt7VSfe6",
        "colab_type": "text"
      },
      "source": [
        "# Parsing the annotation and image arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0xViCYiJk5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_annotation():\n",
        "\n",
        "    colnames = ['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
        "    data = pandas.read_csv('annotation/via_export_csv.csv', names=colnames)\n",
        "\n",
        "    name      = data.filename.tolist()\n",
        "    reg_shape = data.region_shape_attributes.tolist()\n",
        "\n",
        "    all_ann = []\n",
        "    all_img = []\n",
        "    Y_train = [None]*14\n",
        "\n",
        "    cones = 0\n",
        "    dim = [None]*2\n",
        "\n",
        "    while cones < len(name)-1:\n",
        "\n",
        "        try:\n",
        "            cones += 1\n",
        "            \n",
        "            image = cv2.imread(\"images/\"+str(name[cones]))\n",
        "\n",
        "            if image is None:\n",
        "                print(\"File does not exist\")\n",
        "\n",
        "            else:\n",
        "                all_img.append(image[:])\n",
        "                for i in range(7):\n",
        "                    string = reg_shape[cones].split(',')\n",
        "\n",
        "                    for j in range(2):\n",
        "                        temp = string[j+1].split(':')\n",
        "\n",
        "                        if j==1:\n",
        "                            temp[1] = temp[1].replace(\"}\", \"\")\n",
        "                        \n",
        "                        dim[j] = int(temp[1])\n",
        "                    \n",
        "                    x, y = dim[0], dim[1]\n",
        "                    \n",
        "                    Y_train[2*i]   = x\n",
        "                    Y_train[(2*i)+1] = y\n",
        "                    cones += 1\n",
        "\n",
        "                cones -=1\n",
        "                all_ann.append(Y_train[:])\n",
        "        \n",
        "        except FileNotFoundError:\n",
        "            n = name[cones]\n",
        "            if n != t:\n",
        "                print(\"File does not exist\")\n",
        "                t = name[cones]\n",
        "            continue\n",
        "   \n",
        "    return all_img,all_ann\n",
        "\n",
        "def normalize(X_train):\n",
        "    new = []\n",
        "    for i in range(len(X_train)):\n",
        "        new.append(X_train[i]/255.)\n",
        "    return new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWG0VcZpJq9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL6UqrSSKCfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class keypoints(object):\n",
        "    def __init__(self, backend,\n",
        "                       input_size, \n",
        "                       labels,\n",
        "                       classes=14):\n",
        "        \n",
        "        self.X_predicted = [None] * 7\n",
        "        self.Y_predicted = [None] * 7\n",
        "        self.X_groundtruth = [None] * 7\n",
        "        self.Y_groundtruth = [None] * 7\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        \n",
        "        self.labels   = list(labels)\n",
        "        self.nb_class = len(self.labels)\n",
        "\n",
        "        self.class_wt = np.ones(self.nb_class, dtype='float32')\n",
        "\n",
        "        ##########################\n",
        "        # Make the model\n",
        "        ##########################\n",
        "\n",
        "        # make the feature extractor layers\n",
        "        # input_image = Input(shape=(self.input_size, self.input_size, 3))\n",
        "\n",
        "        base_model = ResNet50(weights= None, include_top=False, input_shape= (self.input_size,self.input_size,3))\n",
        "\n",
        "        x = base_model.output\n",
        "        x = Flatten()(x)\n",
        "        output = Dense(14, activation='relu', name='fc', kernel_initializer = 'normal')(x)\n",
        "\n",
        "        self.model = Model(inputs = base_model.input, outputs = output)\n",
        "\n",
        "        self.model.summary()\n",
        "\n",
        "\n",
        "    def delta_(self, p1, p2, x, y):\n",
        "        return K.sqrt((x[p1]-x[p1])**2 + (y[p2]-y[p2])**2)\n",
        "\n",
        "    def cross_ratio(self, surf, x, y):\n",
        "        if surf == \"left\":\n",
        "            return (self.delta_(0, 2, x, y)/self.delta_(0, 3, x, y)) / (self.delta_(1, 2, x, y)/self.delta_(1, 3, x, y))\n",
        "        elif surf == \"right\":\n",
        "            return (self.delta_(0, 5, x, y)/self.delta_(0, 6, x, y)) / (self.delta_(4, 5, x, y)/self.delta_(4, 6, x, y))\n",
        "    \n",
        "\n",
        "    def custom_loss(self, groundtruth, pridection):      # ETH custom loss\n",
        "        segma = 0.0001  # Cross ratio controlling factor\n",
        "        Cr3D = 1.39408  # The 3D cross ratio of the cone\n",
        "        loss = 0\n",
        "        \n",
        "        loss = (K.square(pridection-groundtruth))\n",
        "\n",
        "        # for i in range(0, 14, 2):\n",
        "        #     self.X_predicted[int(i/2)] = pridection[i]\n",
        "        #     self.X_groundtruth[int(i/2)] = groundtruth[i]\n",
        "\n",
        "        # for j in range(1, 14, 2):\n",
        "        #     self.Y_predicted[int(j/2)] = pridection[j]\n",
        "        #     self.Y_groundtruth[int(j/2)] = groundtruth[j]\n",
        "        \n",
        "\n",
        "        # for k in range(0,7):\n",
        "        #     loss += (self.X_predicted[k]-self.X_groundtruth[k])**2 + (self.Y_predicted[k]-self.Y_groundtruth[k])**2 + \\\n",
        "        #         segma*((self.cross_ratio(\"left\", self.X_predicted, self.Y_predicted)-Cr3D)**2 + (self.cross_ratio(\"right\", self.X_predicted, self.Y_predicted)-Cr3D)**2)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def load_weights(self, weight_path):\n",
        "        self.model.load_weights(weight_path)\n",
        "\n",
        "    def train(self, train_imgs,     # the list of images to train the model\n",
        "                    train_times,    # the number of time to repeat the training set, often used for small datasets\n",
        "                    nb_epochs,      # number of epoches\n",
        "                    learning_rate,  # the learning rate\n",
        "                    batch_size,     # the size of the batch\n",
        "                    saved_weights_name='best_weights.h5',\n",
        "                    debug=False):     \n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.debug = debug\n",
        "\n",
        "        ############################################\n",
        "        # Make train generators\n",
        "        ############################################  \n",
        "\n",
        "        X_train_orig ,Y_train_orig = parse_annotation()\n",
        "\n",
        "        X_train = np.array(normalize(X_train_orig))\n",
        "        Y_train = np.array(Y_train_orig)\n",
        "\n",
        "        print(\"Shape of X_train is: \" + str(np.array(X_train).shape))\n",
        "        print(\"Shape of Y_train is: \" + str(np.array(Y_train).shape))\n",
        "\n",
        "        ############################################\n",
        "        # Compile the model\n",
        "        ############################################\n",
        "\n",
        "        sgd = SGD(lr=0.0001, momentum=0.9)  \n",
        "        self.model.compile(optimizer = sgd, loss = self.custom_loss, metrics = ['accuracy'])\n",
        "\n",
        "        ############################################\n",
        "        # Make a few callbacks\n",
        "        ############################################\n",
        "\n",
        "        early_stop = EarlyStopping(monitor='val_loss', \n",
        "                           min_delta=0.001, \n",
        "                           patience=3, \n",
        "                           mode='min', \n",
        "                           verbose=1)\n",
        "        checkpoint = ModelCheckpoint(saved_weights_name, \n",
        "                                     monitor='val_loss', \n",
        "                                     verbose=1, \n",
        "                                     save_best_only=True, \n",
        "                                     mode='min', \n",
        "                                     period=1)\n",
        "        tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/'), \n",
        "                                  histogram_freq=0, \n",
        "                                  #write_batch_performance=True,\n",
        "                                  write_graph=True, \n",
        "                                  write_images=False)\n",
        "\n",
        "        ############################################\n",
        "        # Start the training process\n",
        "        ############################################        \n",
        "\n",
        "        self.model.fit(X_train, Y_train, \n",
        "                        epochs = nb_epochs, \n",
        "                        batch_size = self.batch_size,\n",
        "                        callbacks = [checkpoint], \n",
        "                        workers = 3,\n",
        "                        max_queue_size = 8) \n",
        "\n",
        "        self.model.save_weights('weights.h5')\n",
        "\n",
        "\n",
        "    def predict(self, image):\n",
        "        image_h, image_w, _ = image.shape\n",
        "        image = cv2.resize(image, (self.input_size, self.input_size))\n",
        "        image = np.array(normalize(image))\n",
        "\n",
        "        input_image = image[:,:,::-1]\n",
        "        input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        "        points = self.model.predict(input_image)\n",
        "        \n",
        "\n",
        "        return points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TevrIzVPSuuA",
        "colab_type": "text"
      },
      "source": [
        "# Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4fW_Ei_LL5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QeYIK3pLWoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs, train_labels = parse_annotation()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT4le4ZEL5PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(config.json) as config_buffer:    \n",
        "        config = json.loads(config_buffer.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYq7akA1Lc7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kp = keypoints(backend             = config['model']['backend'],\n",
        "                input_size          = config['model']['input_size'], \n",
        "                labels              = config['model']['labels'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uLbY7OXLrlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kp.train(train_imgs         = train_imgs,\n",
        "          train_times        = config['train']['train_times'],\n",
        "          nb_epochs          = config['train']['nb_epochs'], \n",
        "          learning_rate      = config['train']['learning_rate'], \n",
        "          batch_size         = config['train']['batch_size'],\n",
        "          saved_weights_name = config['train']['saved_weights_name'],\n",
        "          debug              = config['train']['debug'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDqPJ7cK9-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kp.load_weights(weights_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1bub4WZTCVL",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzU9-NAzLJFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread(image_path)\n",
        "points = kp.predict(image)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}